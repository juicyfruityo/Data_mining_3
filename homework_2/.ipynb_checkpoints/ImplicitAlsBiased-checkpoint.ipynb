{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sparsesvd import sparsesvd\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.txt', sep='\\t', names=['UserId', 'FilmId', 'Mark'])\n",
    "df_test = pd.read_csv('data/test.txt', sep='\\t', names=['UserId', 'FilmId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplicitAlsBiased(BaseEstimator):\n",
    "    def __init__(self, features=4, iterations=20, alpha=5, eps=0.01, init_mean=0,\n",
    "                 init_std=0.1, lr=0.07, random_state=None, decrease=0.85,\n",
    "                 c_function='linear', use_test=True, substract_mean=True):\n",
    "\n",
    "        self.features = int(features)\n",
    "        self.iterations = int(iterations)\n",
    "        self.init_mean = init_mean\n",
    "        self.init_std = init_std\n",
    "        self.lr = lr\n",
    "\n",
    "        self.random_state = random_state\n",
    "        self.alpha = alpha\n",
    "        self.eps = eps\n",
    "        self.use_test = use_test\n",
    "\n",
    "        self.substract_mean = substract_mean\n",
    "        self.c_function = c_function\n",
    "        self.decrease = decrease\n",
    "\n",
    "        if c_function is 'linear':\n",
    "            self.confidence_func = self.__linear_conf\n",
    "        if c_function is 'log':\n",
    "            self.confidence_func = self.__log_conf\n",
    "\n",
    "    def __linear_conf(self, R):\n",
    "        C = 1 + self.alpha * R\n",
    "        return C\n",
    "\n",
    "    def __log_conf(self, R):\n",
    "        C = 1 + self.alpha * np.log(1 + R / self.eps)\n",
    "        return C\n",
    "    \n",
    "    def __init_decomposition(self, R_train):\n",
    "        u, _, v = sparsesvd(csc_matrix(R_train), self.features)\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "\n",
    "    def __init_X(self, R_train, initialize=False, init_x=None):\n",
    "        X = np.ones((self.n_users, 1 + self.features))\n",
    "        if initialize:\n",
    "            X[:, 1:] = init_x\n",
    "        else:\n",
    "            X = np.hstack([np.ones((R_train.shape[0], 1)), self.u.T])\n",
    "        return X\n",
    "\n",
    "    def __init_Y(self, R_train, initialize=False, init_y=None):\n",
    "        Y = np.ones((self.n_items, 1 + self.features))\n",
    "        if initialize:\n",
    "            Y[:, 1:] = init_y\n",
    "        else:\n",
    "            Y = np.hstack([np.ones((R_train.shape[1], 1)), self.v.T])\n",
    "        return Y\n",
    "\n",
    "    def __parse_df(self, df, train=True):\n",
    "        R = np.zeros(self.shape)\n",
    "        for index, row in df.iterrows():\n",
    "            user_id = int(row[0])\n",
    "            film_id = int(row[1])\n",
    "            if train:\n",
    "                mark = row[2]\n",
    "                R[user_id-1, film_id-1] = mark\n",
    "            else:\n",
    "                R[user_id-1, film_id-1] = 1\n",
    "\n",
    "        return R\n",
    "\n",
    "    def __bias_addition(self, R, R_test):\n",
    "        positive_mask = (R > 0)\n",
    "        zero_mask = R == 0\n",
    "\n",
    "        global_mean = R[positive_mask].mean()\n",
    "        R_globalbias = R * positive_mask - positive_mask * global_mean\n",
    "\n",
    "        user_bias = (R_globalbias.sum(1) / positive_mask.sum(1)).reshape(-1, 1)\n",
    "        R_userbias = R_globalbias * positive_mask - positive_mask * user_bias\n",
    "\n",
    "        film_pos_mask = positive_mask.sum(0)\n",
    "        film_pos_mask[film_pos_mask == 0] = 1\n",
    "        item_bias = (R_userbias.sum(0) / film_pos_mask).reshape(1, -1)\n",
    "\n",
    "        if self.use_test:\n",
    "            test_mask = (R_test > 0)\n",
    "            P = R + zero_mask * (~test_mask) * (user_bias + item_bias + global_mean) * self.decrease + zero_mask * \\\n",
    "                test_mask * (user_bias + item_bias + global_mean)\n",
    "        else:\n",
    "            P = R + zero_mask * (user_bias + item_bias + global_mean) * self.decrease\n",
    "        return P\n",
    "\n",
    "    def fit(self, df_train, df_test=None, valid=False, retrain=False,\n",
    "            initialize=False, init_x=None, init_y=None):\n",
    "        n_users = int(np.max(df_train['UserId'].unique()))\n",
    "        n_movies = int(np.max(df_train['FilmId'].unique()))\n",
    "        self.shape = (n_users, n_movies)\n",
    "\n",
    "        R_train = self.__parse_df(df_train, train=True)\n",
    "        R_test= self.__parse_df(df_test, train=retrain)\n",
    "\n",
    "        n_users = self.shape[0]\n",
    "        n_items = self.shape[1]\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "\n",
    "        not_zero_idx = (R_train > 0)\n",
    "        R_full = R_train + self.decrease * R_test\n",
    "        global_mean = R_train[not_zero_idx].mean()\n",
    "        global_std = R_train[not_zero_idx].std()\n",
    "\n",
    "        if self.use_test:\n",
    "            C = self.confidence_func(R_full)\n",
    "        else:\n",
    "            C = self.confidence_func(R_train)\n",
    "            \n",
    "        # Добавил\n",
    "        C = self.confidence_func(R_train)\n",
    "\n",
    "        self.__init_decomposition(R_train)\n",
    "        X = self.__init_X(R_train, initialize, init_x)\n",
    "        Y = self.__init_Y(R_train, initialize, init_y)\n",
    "\n",
    "        user_bias = np.repeat(0.0, n_users)\n",
    "        item_bias = np.repeat(0.0, n_items)\n",
    "        \n",
    "        numfilms_user = (R_train > 0).sum(1)\n",
    "        numusers_film = (R_train > 0).sum(0)\n",
    "\n",
    "        P = self.__bias_addition(R_train, R_test)\n",
    "\n",
    "        lrI = self.lr * np.eye(self.features + 1, self.features + 1)\n",
    "        self.train_scores = []\n",
    "        self.test_scores = []\n",
    "\n",
    "        for num_epoch in trange(self.iterations):\n",
    "            Pbeta = P - user_bias[:, None]\n",
    "            Pgamma = P - item_bias[None, :]\n",
    "\n",
    "            # Users\n",
    "            Y[:, 0] = np.ones(n_items)\n",
    "            X[:, 0] = np.ones(n_users)\n",
    "\n",
    "            Yt = Y.T\n",
    "            YtY = np.matmul(Yt, Y)\n",
    "            for u in range(n_users):\n",
    "                inv = YtY + np.matmul(Yt * (C[u, :] - 1), Y) + lrI * (numfilms_user[u])\n",
    "                inv_mat = np.linalg.inv(inv)\n",
    "                a = np.matmul(Yt * C[u, :], Pgamma[u, :])\n",
    "                X[u, :] = np.matmul(inv_mat, a)\n",
    "            user_bias = np.copy(X[:, 0])\n",
    "            \n",
    "            Pbeta = P - user_bias[:, None]\n",
    "            Pgamma = P - item_bias[None, :]\n",
    "\n",
    "            # Items\n",
    "            X[:, 0] = np.ones(n_users)\n",
    "            Y[:, 0] = np.ones(n_items)\n",
    "\n",
    "            Xt = X.T\n",
    "            XtX = np.matmul(Xt, X)\n",
    "            for i in range(n_items):\n",
    "                inv = XtX + np.matmul(Xt * (C[:, i] - 1), X) + lrI * (numusers_film[i])\n",
    "                inv_mat = np.linalg.inv(inv)\n",
    "                a = np.matmul(Xt * C[:, i], Pbeta[:, i])\n",
    "                Y[i, :] = np.matmul(inv_mat, a)\n",
    "            item_bias = np.copy(Y[:, 0])\n",
    "\n",
    "            self.user_bias = user_bias\n",
    "            self.item_bias = item_bias\n",
    "            self.X = X[:, 1:]\n",
    "            self.Y = Y[:, 1:]\n",
    "            self.global_mean = global_mean\n",
    "            self.global_std = global_std\n",
    "\n",
    "            if valid:\n",
    "                test_score = self.score(df_test.iloc[:, :2].values,\n",
    "                                        df_test.iloc[:, 2].values)\n",
    "                train_score = self.score(df_train.iloc[:, :2].values,\n",
    "                                         df_train.iloc[:, 2].values)\n",
    "                self.train_scores.append(train_score)\n",
    "                self.test_scores.append(test_score)\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        score = 0\n",
    "#         score += self.global_mean\n",
    "        score += self.user_bias[test_data[:, 0].astype(int)-1]\n",
    "        score += self.item_bias[test_data[:, 1].astype(int)-1]\n",
    "        score += (self.X[test_data[:, 0].astype(int)-1] *\n",
    "                  self.Y[test_data[:, 1].astype(int)-1]).sum(1)\n",
    "        return score\n",
    "\n",
    "    def score(self, test_data, y_test):\n",
    "        y_pred = self.predict(test_data)\n",
    "        return np.sqrt(np.mean((y_test - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanModel:\n",
    "    def __init__(self, *models):\n",
    "        self.models = models\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        results = np.zeros(test_data.shape[0])\n",
    "        for model in self.models:\n",
    "            results += model.predict(test_data)\n",
    "        \n",
    "        results = results / float(len(self.models))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ials1 = ImplicitAlsBiased(iterations=35, features=6, lr=7.5, alpha=35, eps=0.1)\n",
    "ials2 = ImplicitAlsBiased(iterations=35, features=15, lr=9.5, alpha=35, eps=0.1)\n",
    "ials3 = ImplicitAlsBiased(iterations=40, features=4, lr=2, alpha=25, eps=0.1)\n",
    "ials5 = ImplicitAlsBiased(iterations=50, features=3, lr=5, alpha=35, eps=0.1)\n",
    "ials6 = ImplicitAlsBiased(iterations=70, features=15, lr=9, alpha=35, eps=0.1)\n",
    "ials10 = ImplicitAlsBiased(iterations=80, features=15, lr=7, alpha=40, eps=0.1)\n",
    "ials13 = ImplicitAlsBiased(iterations=50, features=4, lr=10, alpha=25, eps=0.1)\n",
    "ials14 = ImplicitAlsBiased(iterations=100, features=12, lr=9, alpha=30, eps=0.1)\n",
    "\n",
    "ials1.fit(df_train, df_test)\n",
    "ials2.fit(df_train, df_test)\n",
    "ials3.fit(df_train, df_test)\n",
    "ials5.fit(df_train, df_test)\n",
    "ials6.fit(df_train, df_test)\n",
    "ials10.fit(df_train, df_test)\n",
    "ials13.fit(df_train, df_test)\n",
    "ials14.fit(df_train, df_test)\n",
    "\n",
    "clf_ials_mean = MeanModel(*[ials1, ials2, ials3, ials5, ials6, ials10, ials13, ials14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv('data/sample.txt', sep=',')\n",
    "\n",
    "def make_submission(clf, name='submission_v0'):\n",
    "    \n",
    "    test_data = df_test.values\n",
    "    \n",
    "    marks = clf.predict(test_data)\n",
    "    \n",
    "    marks[marks < 1] = 1\n",
    "    marks[marks > 5] = 5\n",
    "\n",
    "    sample = df_sample.copy()\n",
    "    sample.iloc[:, 1] = marks\n",
    "    \n",
    "    name = 'results/' + name + '.csv'\n",
    "    sample.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(clf_ials_mean, 'subm_ials_mean_v8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
