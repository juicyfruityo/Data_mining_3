{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import california_housing\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Задача: построить алгоритма градиентного бустинга с квадратичной функцией потерь, в качестве базового алгоритма использовать алгоритм CART.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeRegr:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.0, max_features=None, random_state=None,\n",
    "                 max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_impurity_split = min_impurity_split\n",
    "        \n",
    "        self.tree = dict()  # Номер узла: информация об узле.\n",
    "        \n",
    "        self.Leaf = True\n",
    "        self.notLeaf = False\n",
    "        \n",
    "    def _calculate_impurity(self, y):\n",
    "        return np.var(y)\n",
    "        \n",
    "#     def _search_split(self, X, y):\n",
    "#         best_criterion = float('-inf')\n",
    "#         best_feature = None\n",
    "#         best_threshold = None\n",
    "        \n",
    "#         node_impurity = self._calculate_impurity(y)\n",
    "        \n",
    "#         for col in range(X.shape[1]):\n",
    "#             feature_level = np.unique(X[:, col])\n",
    "# #             thresholds = X[:, col]\n",
    "#             # TODO: не очень понимаю зач здесь так сделано, надо разобраться.\n",
    "#             thresholds = (feature_level[1:] + feature_level[:-1]) / 2.0\n",
    "            \n",
    "#             for threshold in thresholds:\n",
    "#                 y_left = y[X[:, col] <= threshold]\n",
    "#                 left_impurity = self._calculate_impurity(y_left)\n",
    "#                 N_left = y_left.shape[0] / y.shape[0]\n",
    "                \n",
    "#                 y_right = y[X[:, col] > threshold]\n",
    "#                 right_impurity = self._calculate_impurity(y_right)\n",
    "#                 N_right = y_right.shape[0] / y.shape[0]\n",
    "                \n",
    "#                 impurity_criterion = node_impurity - N_left * left_impurity \\\n",
    "#                                     - N_right * right_impurity\n",
    "                    \n",
    "#                 if impurity_criterion > best_criterion:\n",
    "#                     best_criterion = impurity_criterion\n",
    "#                     best_feature = col\n",
    "#                     best_threshold = threshold\n",
    "        \n",
    "#         if best_criterion == float('-inf'):\n",
    "#             return best_feature, best_threshold, False\n",
    "                    \n",
    "#         return best_feature, best_threshold, True \n",
    "\n",
    "    def _search_split(self, X, y):\n",
    "        sorted_idx = np.argsort(X, axis=0)\n",
    "        sortedX = np.sort(X, axis=0)\n",
    "        sortedY = y[sorted_idx]\n",
    "        \n",
    "        # Дисперсии для левого поддерева и правого\n",
    "        # объединяются вместе.\n",
    "        sumY = np.cumsum(sortedY, axis=0)\n",
    "        sumY_2 = np.cumsum(sortedY**2, axis=0)\n",
    "        revsumY = np.cumsum(sortedY[::-1], axis=0)[::-1]\n",
    "        revsumY_2 = np.cumsum(sortedY[::-1]**2, axis=0)[::-1]\n",
    "        \n",
    "        length = np.array(range(1, X.shape[0]+1)).reshape(-1, 1)\n",
    "        left_crit = sumY_2 - 2 * sumY**2 / length + sumY**2 / length**2\n",
    "        right_crit = revsumY_2 - 2 * revsumY**2 / length[::-1] + revsumY**2 / length[::-1]**2\n",
    "        \n",
    "        crit = left_crit\n",
    "        # Т.к. разделение в правую ветку идет со знаком <.\n",
    "        crit[:-1] += right_crit[1:]\n",
    "        \n",
    "        # Удалить неинформативные фичи.\n",
    "        bad_idx = np.where(np.max(sortedX, axis=0) - np.min(sortedX, axis=0) <= 0.0001)[0]\n",
    "        if bad_idx.shape[0] > 0:\n",
    "            crit[:, bad_idx] = np.nan\n",
    "        \n",
    "#         close_feats = np.isclose(sortedX, np.roll(sortedX, shift=-1, axis=0))\n",
    "#         crit[close_feats] = np.nan\n",
    "#         bad_idx = np.hstack([bad_idx, close_feats])\n",
    "        \n",
    "        # Если все фичи неинформативные, то надо строить лист.\n",
    "        if bad_idx.shape[0] == X.shape[1]:\n",
    "            return None, None, False\n",
    "        \n",
    "        feat_flat_idx = np.nanargmin(crit)\n",
    "        thrl_id, feat_id = np.unravel_index(feat_flat_idx, crit.shape)\n",
    "        \n",
    "        return feat_id, sortedX[thrl_id, feat_id], True\n",
    "        \n",
    "    def _fit_node(self, X, y, node_id, depth):\n",
    "        # Если выполнен критерий остановки, создать листовую вершину.\n",
    "        if (X.shape[0] < self.min_samples_split or depth == self.max_depth):\n",
    "            self.tree[node_id] = [self.Leaf, np.mean(y)]\n",
    "            return\n",
    "        \n",
    "        feature_id, threshold, isOkay = self._search_split(X, y)\n",
    "        \n",
    "        # Значит скорее всего все фичи уже одинаковые в этом поддереве, двигаться некуда.\n",
    "        if isOkay is False:\n",
    "            self.tree[node_id] = [self.Leaf, np.mean(y)]\n",
    "            return\n",
    "        \n",
    "        X_left, y_left = X[X[:, feature_id] >= threshold], y[X[:, feature_id] >= threshold]\n",
    "        X_right, y_right = X[X[:, feature_id] < threshold], y[X[:, feature_id] < threshold]\n",
    "        \n",
    "        if (X_left.shape[0] < self.min_samples_leaf or\n",
    "            X_right.shape[0] < self.min_samples_leaf):\n",
    "\n",
    "            self.tree[node_id] = [self.Leaf, np.mean(y)]            \n",
    "        else:\n",
    "            self.tree[node_id] = [self.notLeaf, feature_id, threshold]\n",
    "            self._fit_node(X_left, y_left, 2*node_id+1, depth+1)\n",
    "            self._fit_node(X_right, y_right, 2*node_id+2, depth+1)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        self._fit_node(X, y, 0, 0)\n",
    "        \n",
    "    def _predict(self, X, node_id):\n",
    "        node_info = self.tree[node_id]\n",
    "        answer = np.zeros(X.shape[0])\n",
    "\n",
    "        if node_info[0] is self.notLeaf:\n",
    "            feature_id, threshold = node_info[1], node_info[2]\n",
    "\n",
    "            ids_left = np.where(X[:, feature_id] >= threshold)\n",
    "            answer[ids_left] = self._predict(X[ids_left], 2*node_id+1)\n",
    "\n",
    "            ids_right = np.where(X[:, feature_id] < threshold)\n",
    "            answer[ids_right] = self._predict(X[ids_right], 2*node_id+2)\n",
    "        else:\n",
    "            answer = np.array([node_info[1]] * X.shape[0])\n",
    "            \n",
    "        return answer\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return self._predict(X, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeRegrNew:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.0, max_features=None, random_state=None,\n",
    "                 max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_impurity_split = min_impurity_split\n",
    "        \n",
    "        self.tree = dict()  # Номер узла: информация об узле.\n",
    "        \n",
    "        self.Leaf = True\n",
    "        self.notLeaf = False\n",
    "        \n",
    "    def _calculate_impurity(self, y):\n",
    "        return np.var(y)\n",
    "\n",
    "    def _search_split(self, x, y):\n",
    "        sorted_idx = x.argsort(axis=0)\n",
    "        sortX, sortY = np.sort(x, axis=0), y[sorted_idx]\n",
    "\n",
    "        cumsumY2 = np.cumsum(sortY ** 2, axis=0)\n",
    "        cumsumRevY2 = np.cumsum(sortY[::-1] ** 2, axis=0)[::-1]\n",
    "\n",
    "        cumsumY = np.cumsum(sortY, axis=0)\n",
    "        cumsumRevY = np.cumsum(sortY[::-1], axis=0)[::-1]\n",
    "\n",
    "        lenArray = np.array(range(1, cumsumY.shape[0] + 1)).reshape(-1, 1)\n",
    "#         left = cumsumY2 - cumsumY ** 2 / lenArray\n",
    "#         right = cumsumRevY2 - cumsumRevY ** 2 / lenArray[::-1]\n",
    "        left = cumsumY2 - 2 * cumsumY ** 2 / lenArray + cumsumY ** 2 / lenArray**2\n",
    "        right = cumsumRevY2 - 2 * cumsumRevY ** 2 / lenArray[::-1] + cumsumRevY ** 2 / lenArray[::-1]**2\n",
    "\n",
    "        mse = left\n",
    "        mse[:-1] += right[1:]\n",
    "        \n",
    "        # удаляем бесполезные фичи\n",
    "        bad_features = np.where((np.max(x, axis=0) - np.min(x, axis=0)) < 1e-3)[0]\n",
    "        mse[:, bad_features] = np.nan\n",
    "        # если две фичи рядом очень похожи между собой, то надо выкинуть фичу -> пропускаем очень близкие значения\n",
    "        # np.isclose - возвращает логический массив, где два массива поэлементно равны в пределах допуска\n",
    "        mse[np.isclose(sortX, np.roll(sortX, shift=-1, axis=0))] = np.nan\n",
    "        # если ошибка - значит топ сплита нет - и мы переобучимся - делаем резкий \n",
    "        \n",
    "        try:\n",
    "            argmin = np.nanargmin(mse)\n",
    "        except ValueError:\n",
    "            return None, None, False\n",
    "        \n",
    "        # получаем номер объекта и фичу лучшего сплита\n",
    "        idx = argmin // mse.shape[1]\n",
    "        feature_id = argmin - idx*mse.shape[1]\n",
    "        \n",
    "        threshold = sortX[idx, feature_id]\n",
    "        \n",
    "        return feature_id, threshold, True\n",
    "        \n",
    "    def _fit_node(self, X, y, node_id, depth):\n",
    "        # Если выполнен критерий остановки, создать листовую вершину.\n",
    "        if (X.shape[0] < self.min_samples_split or depth == self.max_depth):\n",
    "            self.tree[node_id] = [self.Leaf, np.mean(y)]\n",
    "            return\n",
    "        \n",
    "        feature_id, threshold, isOkay = self._search_split(X, y)\n",
    "        \n",
    "        # Значит скорее всего все фичи уже одинаковые в этом поддереве, двигаться некуда.\n",
    "        if isOkay is False:\n",
    "            self.tree[node_id] = [self.Leaf, np.mean(y)]\n",
    "            return\n",
    "        \n",
    "        X_left, y_left = X[X[:, feature_id] >= threshold], y[X[:, feature_id] >= threshold]\n",
    "        X_right, y_right = X[X[:, feature_id] < threshold], y[X[:, feature_id] < threshold]\n",
    "        \n",
    "        if (X_left.shape[0] < self.min_samples_leaf or\n",
    "            X_right.shape[0] < self.min_samples_leaf):\n",
    "\n",
    "            self.tree[node_id] = [self.Leaf, np.mean(y)]            \n",
    "        else:\n",
    "            self.tree[node_id] = [self.notLeaf, feature_id, threshold]\n",
    "            self._fit_node(X_left, y_left, 2*node_id+1, depth+1)\n",
    "            self._fit_node(X_right, y_right, 2*node_id+2, depth+1)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        self._fit_node(X, y, 0, 0)\n",
    "        \n",
    "    def _predict(self, X, node_id):\n",
    "        node_info = self.tree[node_id]\n",
    "        answer = np.zeros(X.shape[0])\n",
    "\n",
    "        if node_info[0] is self.notLeaf:\n",
    "            feature_id, threshold = node_info[1], node_info[2]\n",
    "\n",
    "            ids_left = np.where(X[:, feature_id] >= threshold)\n",
    "            answer[ids_left] = self._predict(X[ids_left], 2*node_id+1)\n",
    "\n",
    "            ids_right = np.where(X[:, feature_id] < threshold)\n",
    "            answer[ids_right] = self._predict(X[ids_right], 2*node_id+2)\n",
    "        else:\n",
    "            answer = np.array([node_info[1]] * X.shape[0])\n",
    "            \n",
    "        return answer\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return self._predict(X, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \"\"\"\n",
    "        author: Michael Pritugin\n",
    "    \"\"\"\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, max_features=None, min_samples_leaf=1):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sort_samples(x, y):\n",
    "        sorted_idx = x.argsort(axis=0)\n",
    "        return np.sort(x, axis=0), y[sorted_idx]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _div_samples(x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] <= threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        if (x.shape[0] < self.min_samples_split) or (depth == self.max_depth):\n",
    "            self.tree[node_id] = self.LEAF_TYPE, np.mean(y)\n",
    "            return\n",
    "\n",
    "        sortX, sortY = DecisionTree._sort_samples(x, y)\n",
    "\n",
    "        cumsumY2 = np.cumsum(sortY ** 2, axis=0)\n",
    "        cumsumRevY2 = np.cumsum(sortY[::-1] ** 2, axis=0)[::-1]\n",
    "\n",
    "        cumsumY = np.cumsum(sortY, axis=0)\n",
    "        cumsumRevY = np.cumsum(sortY[::-1], axis=0)[::-1]\n",
    "\n",
    "        lenArray = np.array(range(1, cumsumY.shape[0] + 1)).reshape(-1, 1)\n",
    "#         left = cumsumY2 - cumsumY ** 2 / lenArray\n",
    "#         right = cumsumRevY2 - cumsumRevY ** 2 / lenArray[::-1]\n",
    "        left = cumsumY2 - 2 * cumsumY ** 2 / lenArray + cumsumY ** 2 / lenArray**2\n",
    "        right = cumsumRevY2 - 2 * cumsumRevY ** 2 / lenArray[::-1] + cumsumRevY ** 2 / lenArray[::-1]**2\n",
    "\n",
    "        mse = left\n",
    "        mse[:-1] += right[1:]\n",
    "        \n",
    "        # удаляем бесполезные фичи\n",
    "        bad_features = np.where((np.max(x, axis=0) - np.min(x, axis=0)) < 1e-3)[0]\n",
    "        mse[:, bad_features] = np.nan\n",
    "        # если две фичи рядом очень похожи между собой, то надо выкинуть фичу -> пропускаем очень близкие значения\n",
    "        # np.isclose - возвращает логический массив, где два массива поэлементно равны в пределах допуска\n",
    "        mse[np.isclose(sortX, np.roll(sortX, shift=-1, axis=0))] = np.nan\n",
    "        # если ошибка - значит топ сплита нет - и мы переобучимся - делаем резкий \n",
    "        \n",
    "        try:\n",
    "            argmin = np.nanargmin(mse)\n",
    "        except ValueError:\n",
    "            self.tree[node_id] = self.LEAF_TYPE, np.mean(y)\n",
    "            return\n",
    "        \n",
    "        # получаем номер объекта и фичу лучшего сплита\n",
    "        idx = argmin // mse.shape[1]\n",
    "        feature_id = argmin - idx*mse.shape[1]\n",
    "        \n",
    "        threshold = sortX[idx, feature_id]\n",
    "        # логика построения дерева\n",
    "        Xleft, Xright, Yleft, Yright = self._div_samples(x, y, feature_id, threshold)\n",
    "\n",
    "        if Xleft.shape[0] < self.min_samples_leaf or Xright.shape[0] < self.min_samples_leaf:\n",
    "            self.tree[node_id] = self.LEAF_TYPE, np.mean(y)\n",
    "        else:\n",
    "            self.tree[node_id] = self.NON_LEAF_TYPE, feature_id, threshold\n",
    "            \n",
    "            self.__fit_node(Xleft, Yleft, 2 * node_id + 1, depth + 1)\n",
    "            self.__fit_node(Xright, Yright, 2 * node_id + 2, depth + 1)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.__fit_node(X, y, 0, 0)\n",
    "        return self\n",
    "\n",
    "    def __predict(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        answer = np.zeros(x.shape[0])\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            left_idx = np.where(x[:, feature_id] <= threshold)\n",
    "            right_idx = np.where(x[:, feature_id] > threshold)\n",
    "\n",
    "            answer[left_idx] = self.__predict(x[left_idx], 2*node_id + 1)\n",
    "            answer[right_idx] = self.__predict(x[right_idx], 2*node_id + 2)\n",
    "            return answer\n",
    "        \n",
    "        \n",
    "        return np.array([node[1]]*x.shape[0])\n",
    "            \n",
    "    def predict(self, X):\n",
    "        x = X\n",
    "        answer = self.__predict(X, 0)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4])\n",
    "np.hstack([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.036375000000003, 13.619499999999999, 17.154999999999998, 21.00814729574223, 18.285696202531646]\n",
      "18.620943699654777\n",
      "CPU times: user 336 ms, sys: 41 µs, total: 336 ms\n",
      "Wall time: 335 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "for train_id, test_id in kf.split(X, y):\n",
    "    X_train, y_train = X[train_id], y[train_id]\n",
    "    X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "    mytree_ex = MyDecisionTreeRegrNew()\n",
    "    mytree_ex.fit(X_train, y_train)\n",
    "\n",
    "    y_res = mytree_ex.predict(X_test)\n",
    "    results.append(mean_squared_error(y_test, y_res))\n",
    "\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.83508491403495, 12.525776175240726, 11.880222248888362, 12.486017729397638, 13.619292409841883]\n",
      "14.06927869548071\n",
      "CPU times: user 22.2 ms, sys: 0 ns, total: 22.2 ms\n",
      "Wall time: 21.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "for train_id, test_id in kf.split(X, y):\n",
    "    X_train, y_train = X[train_id], y[train_id]\n",
    "    X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "    mytree_ex = DecisionTree()\n",
    "    mytree_ex.fit(X_train, y_train)\n",
    "\n",
    "    y_res = mytree_ex.predict(X_test)\n",
    "    results.append(mean_squared_error(y_test, y_res))\n",
    "    \n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year\n",
       "0  18.0        8.0         307.0       130.0  3504.0          12.0  70.0\n",
       "1  15.0        8.0         350.0       165.0  3693.0          11.5  70.0\n",
       "2  18.0        8.0         318.0       150.0  3436.0          11.0  70.0\n",
       "3  16.0        8.0         304.0       150.0  3433.0          12.0  70.0\n",
       "4  17.0        8.0         302.0       140.0  3449.0          10.5  70.0"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin', 'name']\n",
    "data = pd.read_csv('auto-mpg.data', delim_whitespace=True, names=names)\n",
    "\n",
    "data['horsepower'].replace('?', -999, inplace=True)\n",
    "data[['cylinders', 'year', 'origin', 'horsepower']] = data[['cylinders', 'year', 'origin', 'horsepower']\n",
    "                                                          ].astype(np.float32)\n",
    "data.drop(['origin', 'name'], axis=1, inplace=True)\n",
    "\n",
    "X, y = data.iloc[:, 1:], data.iloc[:, 0]\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.414813947135647, 14.695552884449706, 13.400787812853675, 15.50393538086141, 12.129899869737478]\n",
      "13.228997979007584\n",
      "CPU times: user 86.3 ms, sys: 4.12 ms, total: 90.4 ms\n",
      "Wall time: 92.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "for train_id, test_id in kf.split(X, y):\n",
    "    X_train, y_train = X[train_id], y[train_id]\n",
    "    X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "    mytree_ex = MyDecisionTreeRegr()\n",
    "    mytree_ex.fit(X_train, y_train)\n",
    "\n",
    "    y_res = mytree_ex.predict(X_test)\n",
    "    results.append(mean_squared_error(y_test, y_res))\n",
    "\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.422500000000003, 11.460250000000002, 19.699, 9.181265822784813, 11.206835443037976]\n",
      "14.393970253164559\n",
      "CPU times: user 6.84 ms, sys: 0 ns, total: 6.84 ms\n",
      "Wall time: 6.24 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "for train_id, test_id in kf.split(X, y):\n",
    "    X_train, y_train = X[train_id], y[train_id]\n",
    "    X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "    tree_ex = DecisionTreeRegressor()\n",
    "    tree_ex.fit(X_train, y_train)\n",
    "\n",
    "    y_res_ex = tree_ex.predict(X_test)\n",
    "    results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево вроде работает нормально, но долго, скорее всего из-за np.unique и все такое.\n",
    "\n",
    "Дальше забабахаем градиентный бустинг на этих деревьях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class constanta:\n",
    "    def fit(self, X, y):\n",
    "        self.result = np.mean(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGradientBoostingRegr:\n",
    "    def __init__(self, learning_rate=0.1, n_estimators=100, subsample=1.0,\n",
    "                 min_samples_split=2, min_samples_leaf=1,\n",
    "                 max_depth=3, alpha=0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators + 1  # +1 для константы.\n",
    "        self.subsample = subsample\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_depth = max_depth\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.estimators = []\n",
    "        self.weights = []\n",
    "        \n",
    "    def _calculate_weight(self, G_ij, X, h_next):\n",
    "        y_pred = h_next.predict(X)\n",
    "        weights = G_ij / y_pred\n",
    "        \n",
    "        return np.mean(weights)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "#         h_curr = constanta()\n",
    "#         h_curr = MyDecisionTreeRegrNew(max_depth=3)\n",
    "        h_curr = DecisionTree(max_depth=3)\n",
    "        h_curr.fit(X, y)\n",
    "        w_curr = 1.0 * 1  #self.learning_rate\n",
    "        self.estimators.append(h_curr)\n",
    "        self.weights.append(w_curr)\n",
    "        \n",
    "        G_ij = y\n",
    "        \n",
    "        for i in range(1, self.n_estimators):\n",
    "            if i % 30 == 0:\n",
    "                self.max_depth += 1\n",
    "            \n",
    "            y_pred = h_curr.predict(X) * w_curr\n",
    "            G_ij = G_ij - y_pred\n",
    "            \n",
    "#             h_next = MyDecisionTreeRegrNew(max_depth=self.max_depth)\n",
    "            h_next = DecisionTree(max_depth=self.max_depth)\n",
    "            h_next.fit(X, G_ij)\n",
    "            \n",
    "            w_next = self._calculate_weight(G_ij, X, h_next) * self.learning_rate\n",
    "            \n",
    "            self.estimators.append(h_next)\n",
    "            self.weights.append(w_next)\n",
    "            \n",
    "            h_curr = h_next\n",
    "            w_curr = w_next\n",
    "\n",
    "    def predict(self, X):\n",
    "        answer = np.zeros(X.shape[0])\n",
    "        for i in range(self.n_estimators):\n",
    "            answer += self.weights[i] * self.estimators[i].predict(X)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Контрольная проверка, сравнение бустингов на 5 случайно пошафленных вариантов данных Auto-mpg, с валидацией по 5 фолдов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "results_test = []\n",
    "\n",
    "for i in range(5):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    results = []\n",
    "    for train_id, test_id in kf.split(X, y):\n",
    "        X_train, y_train = X[train_id], y[train_id]\n",
    "        X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "        my_gbr = MyGradientBoostingRegr()\n",
    "        my_gbr.fit(X_train, y_train)\n",
    "\n",
    "        y_res_ex = my_gbr.predict(X_test)\n",
    "        results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "    results_test.append(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_valid = []\n",
    "\n",
    "for i in range(5):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    results = []\n",
    "    for train_id, test_id in kf.split(X, y):\n",
    "        X_train, y_train = X[train_id], y[train_id]\n",
    "        X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "        gbr = GradientBoostingRegressor()\n",
    "        gbr.fit(X_train, y_train)\n",
    "\n",
    "        y_res_ex = gbr.predict(X_test)\n",
    "        results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "    results_valid.append(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты тестового градиентного бстинга:\n",
      "[12.708354276158309, 12.708354276158309, 12.708354276158309, 12.708354276158309, 12.708354276158309]\n",
      "\n",
      "Результаты валидационного градиентного бстинга:\n",
      "[8.419915555798287, 8.401905560039898, 8.478585763826114, 8.52594547597791, 8.492341034999306]\n"
     ]
    }
   ],
   "source": [
    "print(\"Результаты тестового градиентного бстинга:\")\n",
    "print(results_test)\n",
    "print(\"\\nРезультаты валидационного градиентного бстинга:\")\n",
    "print(results_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>myct</th>\n",
       "      <th>mmin</th>\n",
       "      <th>mmax</th>\n",
       "      <th>cach</th>\n",
       "      <th>chmin</th>\n",
       "      <th>chmax</th>\n",
       "      <th>prp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    myct    mmin     mmax   cach  chmin  chmax    prp\n",
       "0  125.0   256.0   6000.0  256.0   16.0  128.0  198.0\n",
       "1   29.0  8000.0  32000.0   32.0    8.0   32.0  269.0\n",
       "2   29.0  8000.0  32000.0   32.0    8.0   32.0  220.0\n",
       "3   29.0  8000.0  32000.0   32.0    8.0   32.0  172.0\n",
       "4   29.0  8000.0  16000.0   32.0    8.0   16.0  132.0"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['vendor', 'model', 'myct', 'mmin', 'mmax', 'cach', 'chmin', 'chmax', 'prp', 'erp']\n",
    "data = pd.read_csv('machine.data', names=names)\n",
    "\n",
    "data[['myct', 'mmin', 'mmax', 'cach', 'chmin', 'chmax', 'prp']] = data[['myct', 'mmin', 'mmax', 'cach',\n",
    "                                                                        'chmin', 'chmax', 'prp']].astype(np.float32)\n",
    "y_erp = data.iloc[:, -1]\n",
    "data.drop(['vendor', 'model', 'erp'], axis=1, inplace=True)\n",
    "\n",
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "results_test = []\n",
    "\n",
    "for i in range(5):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    results = []\n",
    "    for train_id, test_id in kf.split(X, y):\n",
    "        X_train, y_train = X[train_id], y[train_id]\n",
    "        X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "        my_gbr = MyGradientBoostingRegr()\n",
    "        my_gbr.fit(X_train, y_train)\n",
    "\n",
    "        y_res_ex = my_gbr.predict(X_test)\n",
    "        results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "    results_test.append(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_valid = []\n",
    "\n",
    "for i in range(5):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    results = []\n",
    "    for train_id, test_id in kf.split(X, y):\n",
    "        X_train, y_train = X[train_id], y[train_id]\n",
    "        X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "        gbr = GradientBoostingRegressor()\n",
    "        gbr.fit(X_train, y_train)\n",
    "\n",
    "        y_res_ex = gbr.predict(X_test)\n",
    "        results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "    results_valid.append(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты тестового градиентного бстинга:\n",
      "[8735.651821829833, 8735.651821829833, 8735.651821829833, 8735.651821829833, 8735.651821829833]\n",
      "\n",
      "Результаты валидационного градиентного бстинга:\n",
      "[2230.7257861662715, 2111.4784932409807, 2009.703142471611, 2012.8923023430211, 2012.892446337455]\n"
     ]
    }
   ],
   "source": [
    "print(\"Результаты тестового градиентного бстинга:\")\n",
    "print(results_test)\n",
    "print(\"\\nРезультаты валидационного градиентного бстинга:\")\n",
    "print(results_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1737.3349282296651"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для сравнения ошабка для предсказания от людей, выложивших датасет.\n",
    "mean_squared_error(y, np.array(y_erp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 661 ms, sys: 90 µs, total: 661 ms\n",
      "Wall time: 662 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = []\n",
    "y_train = []\n",
    "with open('Regression dataset/reg.train.txt', 'r') as file:\n",
    "\n",
    "    for line in file:\n",
    "        try:\n",
    "            line = line.rstrip()\n",
    "            buf = line.split()\n",
    "            y = buf[0]\n",
    "            y_train.append(float(y))\n",
    "\n",
    "            x = np.array([-9.0]*245)\n",
    "            for elem in buf[1:-1]:\n",
    "                id, feat = elem.split(':')\n",
    "                x[int(id)-1] = float(feat)\n",
    "            X_train.append(x)\n",
    "        except:\n",
    "            print(line)\n",
    "    \n",
    "    line = file.readline()\n",
    "        \n",
    "    \n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 912 ms, sys: 0 ns, total: 912 ms\n",
      "Wall time: 910 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = []\n",
    "y_test = []\n",
    "with open('Regression dataset/reg.test.txt', 'r') as file:\n",
    "\n",
    "    for line in file:\n",
    "        try:\n",
    "            line = line.rstrip()\n",
    "            buf = line.split()\n",
    "            y = buf[0]\n",
    "            y_test.append(float(y))\n",
    "\n",
    "            x = np.array([-9.0]*245)\n",
    "            for elem in buf[1:-1]:\n",
    "                id, feat = elem.split(':')\n",
    "                x[int(id)-1] = float(feat)\n",
    "            X_test.append(x)\n",
    "        except:\n",
    "            print(line)\n",
    "    \n",
    "    line = file.readline()\n",
    "        \n",
    "    \n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.6365417352784\n",
      "CPU times: user 5.01 s, sys: 12.1 ms, total: 5.03 s\n",
      "Wall time: 5.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_gbr = MyGradientBoostingRegr(n_estimators=300)\n",
    "my_gbr.fit(X_train, y_train)\n",
    "\n",
    "y_res_ex = my_gbr.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_res_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7948611471657767\n",
      "CPU times: user 15.2 s, sys: 4.01 ms, total: 15.2 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbr = GradientBoostingRegressor(n_estimators=300, criterion='mse')\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "y_res_ex = gbr.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_res_ex))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
