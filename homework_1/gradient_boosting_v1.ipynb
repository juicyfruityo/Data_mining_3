{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import california_housing\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Задача: построить алгоритма градиентного бустинга с квадратичной функцией потерь, в качестве базового алгоритма использовать алгоритм CART.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeRegr:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.0, max_features=None, random_state=None,\n",
    "                 max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_impurity_split = min_impurity_split\n",
    "        \n",
    "        self.tree = dict()  # Номер узла: информация об узле.\n",
    "        \n",
    "        self.Leaf = True\n",
    "        self.notLeaf = False\n",
    "        \n",
    "    def _calculate_impurity(self, y):\n",
    "        return np.var(y)\n",
    "        \n",
    "    def _search_split(self, X, y):\n",
    "        best_criterion = float('-inf')\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        \n",
    "        node_impurity = self._calculate_impurity(y)\n",
    "        \n",
    "        for col in range(X.shape[1]):\n",
    "            feature_level = np.unique(X[:, col])\n",
    "            # TODO: не очень понимаю зач здесь так сделано, надо разобраться.\n",
    "            thresholds = (feature_level[1:] + feature_level[:-1]) / 2.0\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                y_left = y[X[:, col] <= threshold]\n",
    "                left_impurity = self._calculate_impurity(y_left)\n",
    "                N_left = y_left.shape[0] / y.shape[0]\n",
    "                \n",
    "                y_right = y[X[:, col] > threshold]\n",
    "                right_impurity = self._calculate_impurity(y_right)\n",
    "                N_right = y_right.shape[0] / y.shape[0]\n",
    "                \n",
    "                impurity_criterion = node_impurity - N_left * left_impurity \\\n",
    "                                    - N_right * right_impurity\n",
    "                    \n",
    "                if impurity_criterion > best_criterion:\n",
    "                    best_criterion = impurity_criterion\n",
    "                    best_feature = col\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        if best_criterion == float('-inf'):\n",
    "            return best_feature, best_threshold, False\n",
    "                    \n",
    "        return best_feature, best_threshold, True\n",
    "        \n",
    "    def _fit_node(self, X, y, node_id, depth):\n",
    "        # Если выполнен критерий остановки, создать листовую вершину.\n",
    "        # Был знк меньше.\n",
    "        if (X.shape[0] <= self.min_samples_split or depth == self.max_depth):\n",
    "            self.tree[node_id] = [self.Leaf, np.mean(y)]\n",
    "            return\n",
    "        \n",
    "        feature_id, threshold, isOkay = self._search_split(X, y)\n",
    "        \n",
    "        # Значит скорее всего все фичи уже одинаковые в этом поддереве, двигаться некуда.\n",
    "        if isOkay is False:\n",
    "            self.tree[node_id] = [self.Leaf, np.mean(y)]\n",
    "            return\n",
    "        \n",
    "        X_left, y_left = X[X[:, feature_id] >= threshold], y[X[:, feature_id] >= threshold]\n",
    "        X_right, y_right = X[X[:, feature_id] < threshold], y[X[:, feature_id] < threshold]\n",
    "        \n",
    "        if (X_left.shape[0] < self.min_samples_leaf or\n",
    "            X_right.shape[0] < self.min_samples_leaf):\n",
    "\n",
    "            self.tree[node_id] = [self.Leaf, np.mean(y)]            \n",
    "        else:\n",
    "            self.tree[node_id] = [self.notLeaf, feature_id, threshold]\n",
    "            self._fit_node(X_left, y_left, 2*node_id+1, depth+1)\n",
    "            self._fit_node(X_right, y_right, 2*node_id+2, depth+1)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        self._fit_node(X, y, 0, 0)\n",
    "        \n",
    "    def _predict(self, X, node_id):\n",
    "        node_info = self.tree[node_id]\n",
    "        answer = np.zeros(X.shape[0])\n",
    "\n",
    "        if node_info[0] is self.notLeaf:\n",
    "            feature_id, threshold = node_info[1], node_info[2]\n",
    "\n",
    "            ids_left = np.where(X[:, feature_id] >= threshold)\n",
    "            answer[ids_left] = self._predict(X[ids_left], 2*node_id+1)\n",
    "\n",
    "            ids_right = np.where(X[:, feature_id] < threshold)\n",
    "            answer[ids_right] = self._predict(X[ids_right], 2*node_id+2)\n",
    "        else:\n",
    "            answer = np.array([node_info[1]] * X.shape[0])\n",
    "            \n",
    "        return answer\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return self._predict(X, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year\n",
       "0  18.0        8.0         307.0       130.0  3504.0          12.0  70.0\n",
       "1  15.0        8.0         350.0       165.0  3693.0          11.5  70.0\n",
       "2  18.0        8.0         318.0       150.0  3436.0          11.0  70.0\n",
       "3  16.0        8.0         304.0       150.0  3433.0          12.0  70.0\n",
       "4  17.0        8.0         302.0       140.0  3449.0          10.5  70.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin', 'name']\n",
    "data = pd.read_csv('auto-mpg.data', delim_whitespace=True, names=names)\n",
    "\n",
    "data['horsepower'].replace('?', -999, inplace=True)\n",
    "data[['cylinders', 'year', 'origin', 'horsepower']] = data[['cylinders', 'year', 'origin', 'horsepower']\n",
    "                                                          ].astype(np.float32)\n",
    "data.drop(['origin', 'name'], axis=1, inplace=True)\n",
    "\n",
    "X, y = data.iloc[:, 1:], data.iloc[:, 0]\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.135, 6.08345, 11.0075, 7.89755, 16.204099999999997, 33.9133, 39.26275510204081, 38.316071428571426]\n",
      "19.602465816326532\n",
      "CPU times: user 2.83 s, sys: 0 ns, total: 2.83 s\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "for train_id, test_id in kf.split(X, y):\n",
    "    X_train, y_train = X[train_id], y[train_id]\n",
    "    X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "    mytree_ex = MyDecisionTreeRegr()\n",
    "    mytree_ex.fit(X_train, y_train)\n",
    "\n",
    "    y_res = mytree_ex.predict(X_test)\n",
    "    results.append(mean_squared_error(y_test, y_res))\n",
    "\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.36, 6.347799999999999, 10.635, 7.741999999999999, 18.238799999999998, 28.568, 44.39244897959185, 33.94938775510204]\n",
      "19.279179591836733\n",
      "CPU times: user 10.6 ms, sys: 0 ns, total: 10.6 ms\n",
      "Wall time: 9.83 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "for train_id, test_id in kf.split(X, y):\n",
    "    X_train, y_train = X[train_id], y[train_id]\n",
    "    X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "    tree_ex = DecisionTreeRegressor()\n",
    "    tree_ex.fit(X_train, y_train)\n",
    "\n",
    "    y_res_ex = tree_ex.predict(X_test)\n",
    "    results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево вроде работает нормально, но долго, скорее всего из-за np.unique и все такое.\n",
    "\n",
    "Дальше забабахаем градиентный бустинг на этих деревьях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class constanta:\n",
    "    def fit(self, X, y):\n",
    "        self.result = np.mean(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGradientBoostingRegr:\n",
    "    def __init__(self, learning_rate=0.1, n_estimators=100, subsample=1.0,\n",
    "                 min_samples_split=2, min_samples_leaf=1,\n",
    "                 max_depth=3, alpha=0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators + 1  # +1 для константы.\n",
    "        self.subsample = subsample\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_depth = max_depth\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.estimators = []\n",
    "        self.weights = []\n",
    "        \n",
    "    def _calculate_weight(self, G_ij, X, h_next):\n",
    "        y_pred = h_next.predict(X)\n",
    "        weights = G_ij / y_pred\n",
    "        \n",
    "        return np.mean(weights)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        h_curr = constanta()\n",
    "        h_curr.fit(X, y)\n",
    "        w_curr = 1.0 * self.learning_rate\n",
    "        self.estimators.append(h_curr)\n",
    "        self.weights.append(w_curr)\n",
    "        \n",
    "        G_ij = y\n",
    "        \n",
    "        for i in range(1, self.n_estimators):\n",
    "            y_pred = h_curr.predict(X) * w_curr\n",
    "            G_ij = G_ij - y_pred\n",
    "            \n",
    "            h_next = MyDecisionTreeRegr(max_depth=3)\n",
    "            h_next.fit(X, G_ij)\n",
    "            \n",
    "            w_next = self._calculate_weight(G_ij, X, h_next) * self.learning_rate\n",
    "            \n",
    "            self.estimators.append(h_next)\n",
    "            self.weights.append(w_next)\n",
    "            \n",
    "            h_curr = h_next\n",
    "            w_curr = w_next\n",
    "\n",
    "    def predict(self, X):\n",
    "        answer = np.zeros(X.shape[0])\n",
    "        for i in range(self.n_estimators):\n",
    "            answer += self.weights[i] * self.estimators[i].predict(X)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = []\n",
    "\n",
    "for i in range(5):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "\n",
    "    results = []\n",
    "    for train_id, test_id in kf.split(X, y):\n",
    "        X_train, y_train = X[train_id], y[train_id]\n",
    "        X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "        my_gbr = MyGradientBoostingRegr()\n",
    "        my_gbr.fit(X_train, y_train)\n",
    "\n",
    "        y_res_ex = my_gbr.predict(X_test)\n",
    "        results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "    results_test.append(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gbr = MyGradientBoostingRegr()\n",
    "my_gbr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.288865138704365"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res = my_gbr.predict(X)\n",
    "mean_squared_error(y, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2888648227232715"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X, y)\n",
    "\n",
    "y_res = gbr.predict(X)\n",
    "mean_squared_error(y, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.082612379988642, 2.8464555782722893, 6.487899218112115, 7.039800559129882, 9.22255892650585, 16.455416890274094, 20.879982613101955, 15.18765405801348]\n",
      "10.275297527924788\n",
      "CPU times: user 1min 5s, sys: 20.2 ms, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "for train_id, test_id in kf.split(X, y):\n",
    "    X_train, y_train = X[train_id], y[train_id]\n",
    "    X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "    my_gbr = MyGradientBoostingRegr()\n",
    "    my_gbr.fit(X_train, y_train)\n",
    "\n",
    "    y_res_ex = my_gbr.predict(X_test)\n",
    "    results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.823105169020543, 2.6904240712670786, 6.05231756973587, 7.2916631068352755, 10.031271119533464, 16.184696004243378, 29.486065887931968, 15.20998135881655]\n",
      "11.346190535923014\n",
      "CPU times: user 179 ms, sys: 0 ns, total: 179 ms\n",
      "Wall time: 178 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "for train_id, test_id in kf.split(X, y):\n",
    "    X_train, y_train = X[train_id], y[train_id]\n",
    "    X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    gbr.fit(X_train, y_train)\n",
    "\n",
    "    y_res_ex = gbr.predict(X_test)\n",
    "    results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Контрольная проверка, сравнение бустингов на 5 случайно пошафленных вариантов данных Auto-mpg, с валидацией по 5 фолдов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = []\n",
    "\n",
    "for i in range(5):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "\n",
    "    results = []\n",
    "    for train_id, test_id in kf.split(X, y):\n",
    "        X_train, y_train = X[train_id], y[train_id]\n",
    "        X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "        my_gbr = MyGradientBoostingRegr()\n",
    "        my_gbr.fit(X_train, y_train)\n",
    "\n",
    "        y_res_ex = my_gbr.predict(X_test)\n",
    "        results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "    results_test.append(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_valid = []\n",
    "\n",
    "for i in range(5):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "\n",
    "    results = []\n",
    "    for train_id, test_id in kf.split(X, y):\n",
    "        X_train, y_train = X[train_id], y[train_id]\n",
    "        X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "        gbr = GradientBoostingRegressor()\n",
    "        gbr.fit(X_train, y_train)\n",
    "\n",
    "        y_res_ex = gbr.predict(X_test)\n",
    "        results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "    results_valid.append(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты тестового градиентного бстинга:\n",
      "[7.710954090268361, 7.710954090268361, 7.710954090268361, 7.710954090268361, 7.710954090268361]\n",
      "\n",
      "Результаты валидационного градиентного бстинга:\n",
      "[7.710954090268361, 7.710954090268361, 7.710954090268361, 7.710954090268361, 7.710954090268361]\n"
     ]
    }
   ],
   "source": [
    "print(\"Результаты тестового градиентного бстинга:\")\n",
    "print(results_test)\n",
    "print(\"\\nРезультаты валидационного градиентного бстинга:\")\n",
    "print(results_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>myct</th>\n",
       "      <th>mmin</th>\n",
       "      <th>mmax</th>\n",
       "      <th>cach</th>\n",
       "      <th>chmin</th>\n",
       "      <th>chmax</th>\n",
       "      <th>prp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    myct    mmin     mmax   cach  chmin  chmax    prp\n",
       "0  125.0   256.0   6000.0  256.0   16.0  128.0  198.0\n",
       "1   29.0  8000.0  32000.0   32.0    8.0   32.0  269.0\n",
       "2   29.0  8000.0  32000.0   32.0    8.0   32.0  220.0\n",
       "3   29.0  8000.0  32000.0   32.0    8.0   32.0  172.0\n",
       "4   29.0  8000.0  16000.0   32.0    8.0   16.0  132.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['vendor', 'model', 'myct', 'mmin', 'mmax', 'cach', 'chmin', 'chmax', 'prp', 'erp']\n",
    "data = pd.read_csv('machine.data', names=names)\n",
    "\n",
    "data[['myct', 'mmin', 'mmax', 'cach', 'chmin', 'chmax', 'prp']] = data[['myct', 'mmin', 'mmax', 'cach',\n",
    "                                                                        'chmin', 'chmax', 'prp']].astype(np.float32)\n",
    "y_erp = data.iloc[:, -1]\n",
    "data.drop(['vendor', 'model', 'erp'], axis=1, inplace=True)\n",
    "\n",
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = []\n",
    "\n",
    "for i in range(5):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "\n",
    "    results = []\n",
    "    for train_id, test_id in kf.split(X, y):\n",
    "        X_train, y_train = X[train_id], y[train_id]\n",
    "        X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "        my_gbr = MyGradientBoostingRegr()\n",
    "        my_gbr.fit(X_train, y_train)\n",
    "\n",
    "        y_res_ex = my_gbr.predict(X_test)\n",
    "        results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "    results_test.append(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_valid = []\n",
    "\n",
    "for i in range(5):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "\n",
    "    results = []\n",
    "    for train_id, test_id in kf.split(X, y):\n",
    "        X_train, y_train = X[train_id], y[train_id]\n",
    "        X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "        gbr = GradientBoostingRegressor()\n",
    "        gbr.fit(X_train, y_train)\n",
    "\n",
    "        y_res_ex = gbr.predict(X_test)\n",
    "        results.append(mean_squared_error(y_test, y_res_ex))\n",
    "\n",
    "    results_valid.append(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты тестового градиентного бстинга:\n",
      "[2888.2058171334575, 2888.2058171334575, 2888.2058171334575, 2888.2058171334575, 2888.2058171334575]\n",
      "\n",
      "Результаты валидационного градиентного бстинга:\n",
      "[3590.0607738249396, 3740.983603041978, 3955.9502994895533, 3790.802656980109, 3841.5475217413723]\n"
     ]
    }
   ],
   "source": [
    "print(\"Результаты тестового градиентного бстинга:\")\n",
    "print(results_test)\n",
    "print(\"\\nРезультаты валидационного градиентного бстинга:\")\n",
    "print(results_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1737.3349282296651"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для сравнения ошабка для предсказания от людей, выложивших датасет.\n",
    "mean_squared_error(y, np.array(y_erp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
